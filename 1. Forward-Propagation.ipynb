{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by randomly initializing the weights and the biases in the network. We have 6 weights and 3 biases, one for each node in the hidden layer as well as for each node in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "weights = np.around(np.random.uniform(size = 6), decimals = 2)\n",
    "bias    = np.around(np.random.uniform(size = 3), decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.44 0.07 0.91 0.75 0.04 0.2 ]\n",
      "Bias: [0.61 0.4  0.51]\n"
     ]
    }
   ],
   "source": [
    "print('Weights:', weights)\n",
    "print('Bias:', bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the weights and the biases defined for the network, let's compute the output for a given input, $x_1$ and $x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 is 0.5, x2 is 0.85\n"
     ]
    }
   ],
   "source": [
    "x_1 = 0.5\n",
    "x_2 = 0.85\n",
    "print('x1 is {}, x2 is {}'.format(x_1, x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by computing the wighted sum of the inputs, $z_{1, 1}$, at the first node of the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights sum of the inputs at the first node in the hidden layer is 0.8895\n"
     ]
    }
   ],
   "source": [
    "z_11 = x_1 * weights[0] + x_2 * weights[1] + bias[0]\n",
    "print('The weights sum of the inputs at the first node in the hidden layer is', z_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's compute the weighted sum of the inputs, $z_{1, 2}$, at the second node of the hidden layer. Assign the value to z_12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights sum of the inputs at the second node in the hidden layer is 1.4925000000000002\n"
     ]
    }
   ],
   "source": [
    "z_12 = x_1 * weights[2] + x_2 * weights[3] + bias[1]\n",
    "print('The weights sum of the inputs at the second node in the hidden layer is', z_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, assuming a sigmoid activation function, let's compute the activation of the first node, $a_{1,1}$ in the hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build a sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.7087869793423419\n"
     ]
    }
   ],
   "source": [
    "a_11 = sigmoid(z_11)\n",
    "print('The activation of the first node in the hidden layer is', a_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute the activation function of the second node, $a_{1,2}$ in the hidden layer. Assign the values to a_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the second node in the hidden layer is 0.8164532124233763\n"
     ]
    }
   ],
   "source": [
    "a_12 = sigmoid(z_12)\n",
    "print('The activation of the second node in the hidden layer is', a_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these activations will serve as the inputs to the output layer. So let's compute the weighted sum of these input to the node in the output layer. Assign the value to z_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the input at the node in the output layer is 0.701642121658369\n"
     ]
    }
   ],
   "source": [
    "z_2 = a_11 * weights[4] + a_12 * weights[5] + bias[2]\n",
    "print('The weighted sum of the input at the node in the output layer is', z_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compute the output of the network as the activation of the node in the output layer. Assign the value to a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the network for x1 = 0.5 and x2 = 0.85 is 0.6685517510721143\n"
     ]
    }
   ],
   "source": [
    "a_2 = sigmoid(z_2)\n",
    "print('The output of the network for x1 = 0.5 and x2 = 0.85 is', a_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, neural networks for real problems are composed of many hidden layers and many more nodes in each layer. So, we can't continue making predictions using this very inefficient approach of computing the weighted sum at each node and the activation of each node manually.\n",
    "\n",
    "In order to code an automatic way of making predictions, let's generalize our network. A general network would take $n$ inputs, would have many hidden layers, each hidden layer having $m$ nodes, and would have an output layer. Although the network is showing one hidden layer, but we will code the network to have many hidden layers. Similarly, although the network shows an output layer with one node, we will code the network to have more than one node in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by formally defining the structure of the network. We have **n** is *number of inputs*, **num_hidden_layers** is *number of hidden layer*, **m** is *number of node in each hidden layer*, **num_nodes_output** is *num of nodes in the output layer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "num_hidden_layers = 2\n",
    "m = [2, 2]\n",
    "num_nodes_output = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we defined the structure of the network, let's go ahead and initialize the weights and the biases in the network to random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeNetwork(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    num_nodes_previous = num_inputs \n",
    "    network = {}\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output'\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1)\n",
    "            num_nodes = num_nodes_hidden[layer] \n",
    "        \n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node+1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        num_nodes_previous = num_nodes\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use initializeNetwork function to create a network that:\n",
    "    1. 5 input.\n",
    "    2. 3 hidden layer.\n",
    "    3. 3 nodes in the first layer, 2 nodes in the second layer and 3 nodes in the third layer.\n",
    "    4. 1 node in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.15, 0.47, 0.16, 0.98, 0.48]), 'bias': array([0.62])}, 'node_2': {'weights': array([0.58, 0.21, 0.9 , 0.75, 0.15]), 'bias': array([0.99])}, 'node_3': {'weights': array([0.55, 0.31, 0.06, 0.5 , 0.05]), 'bias': array([0.34])}}, 'layer_2': {'node_1': {'weights': array([0.57, 0.14, 0.81]), 'bias': array([0.78])}, 'node_2': {'weights': array([0.46, 0.34, 0.43]), 'bias': array([0.43])}}, 'layer_3': {'node_1': {'weights': array([0.49, 0.23]), 'bias': array([0.14])}, 'node_2': {'weights': array([0.4, 0.6]), 'bias': array([0.77])}, 'node_3': {'weights': array([0.86, 0.6 ]), 'bias': array([0.83])}}, 'output': {'node_1': {'weights': array([0.2 , 0.34, 0.13]), 'bias': array([0.78])}}}\n"
     ]
    }
   ],
   "source": [
    "small_network = initializeNetwork(5, 3, [3,2,3], 1)\n",
    "print(small_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute weighted sum at each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights_sum(input, weights, bias):\n",
    "    return np.sum(input * weights) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate 5 input that we can feed to **small_network**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [0.15 0.74 0.26 0.53 0.01]\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size = 5), decimals = 2)\n",
    "print('The inputs to the network are', inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **compute_weights_sum** function to compute the weighted sum at the first node in the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'layers_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ea421b1189f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnode_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmall_network\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'node_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnode_bias\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0msmall_network\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'node_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bias'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mweighted_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_weights_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The weighted sum of the first node in the first hidden layer is'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweighted_sum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'layers_1'"
     ]
    }
   ],
   "source": [
    "node_weights = small_network['layers_1']['node_1']['weights']\n",
    "node_bias    = small_network['layers_1']['node_1']['bias']\n",
    "weighted_sum = compute_weights_sum(inputs, node_weights, node_bias)\n",
    "print('The weighted sum of the first node in the first hidden layer is', weighted_sum[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute node activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the output of each node is simply a non-linear tranformation of the weighted sum. We use activation function for this mapping. Let's use the sigmoid function as the activation function here. So let's define a function that takes a weighted sum as input and returns the non-linear transformation of the input using the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_activation(weighted_sum):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **node_activation** function to compute the output of the first node in the first hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_activation_result = node_activation(weighted_sum)\n",
    "print('The output of the first node in the first hidden layer is', node_activation_result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final piece of building a neural network that can perform predictions is to put everything together. So let's create a function that applies the compute_weighted_sum and node_activation functions to each node in the network and propagates the data all the way to the output layer and outputs a prediction for each node in the output layer.\n",
    "\n",
    "The way we are going to accomplish this is through the following procedure:\n",
    "\n",
    "    1. Start with the input layer as the input to the first hidden layer.\n",
    "    2. Compute the weighted sum at the nodes of the current layer.\n",
    "    3. Compute the output of the nodes of the current layer.\n",
    "    4. Set the output of the current layer to be the input to the next layer.\n",
    "    5. Move to the next layer in the network.\n",
    "    6. Repeat steps 2 - 4 until we compute the output of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(network, inputs):\n",
    "    layer_inputs = list(inputs)\n",
    "    for layer in network:\n",
    "        layer_data = network[layer]\n",
    "        layer_outputs = []\n",
    "        for layer_node in layer_data:\n",
    "            node_data = layer_data[layer_node]\n",
    "            node_output = node_activation(compute_weights_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals = 4))\n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in the hidden layer number {} is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "        layer_inputs = layer_outputs\n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_propagation_result = forward_propagation(small_network, inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
